\section{Conclusion}
We proposed a new way of approaching visual question answering for images of real life scenery using commonsense knowledge and reasoning. The methodology was applied to the context of autonomous driving, and we showed how we can answer questions about safe actions on the road by reasoning over visual information like a human would. Our experiment demonstrates how the results of a computer vision model can be transformed into logic predicates. These predicates have been proven to be effective at answering questions about the image presented to it. Our approach is not only explainable and alterable, but it is also widely applicable. While we used this experiment to answer questions about autonomous driving, the techniques shown here can easily be applied to images of a different types. A more expansive knowledge base increases the variety of questions that can be asked, and more complex reasoning could allow for more complicated questions to be handled. 